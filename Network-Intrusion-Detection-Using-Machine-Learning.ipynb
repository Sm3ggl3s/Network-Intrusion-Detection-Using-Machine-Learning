{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e7f741d",
   "metadata": {},
   "source": [
    "# Network Intrusion Detection on DataSense: CIC IIoT 2025 (1-Second Windows)\n",
    "\n",
    "This notebook builds a **modular and share-safe** ML pipeline for the **CIC IIoT 2025** (DataSense) dataset.  \n",
    "It supports **1–10 s** window CSVs, synced sensor+network features, and both **binary** and **multiclass** tasks.\n",
    "\n",
    "## ⚙️ Pipeline Overview\n",
    "1. Load and combine the 1-second attack & benign CSVs, then **shuffle** the rows.\n",
    "2. Do **light cleaning** and prepare features.\n",
    "3. Use **ANOVA (f-test)** to rank features and select the most informative ones.\n",
    "4. Use **Stratified K-Fold** cross-validation for robust evaluation.\n",
    "5. Train baseline models:\n",
    "   - Logistic Regression  \n",
    "   - SVM (RBF)  \n",
    "   - Random Forest  \n",
    "6. Train additional models:\n",
    "   - K-Means clustering (unsupervised ⇒ mapped to labels)  \n",
    "   - K-Nearest Neighbors (KNN)  \n",
    "   - LightGBM (if installed)  \n",
    "   - XGBoost (if installed)\n",
    "7. Compare models using:\n",
    "   - Accuracy  \n",
    "   - **Macro F1-score** (primary)  \n",
    "   - Full classification report  \n",
    "   - Confusion matrix for the best model\n",
    "\n",
    "\n",
    "**Dependencies:** `python-dotenv`, `pandas`, `numpy`, `scikit-learn`, `matplotlib`, `seaborn`, `joblib`, `lightgbm`, `imbalanced-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f19879c-6ad7-4549-bb28-6686365319b5",
   "metadata": {},
   "source": [
    "### Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0824cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Imports & configuration\n",
    "import os\n",
    "import warnings\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_recall_fscore_support,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2d5c87",
   "metadata": {},
   "source": [
    "### 1. Load & Combine 1-Second CSVs (Shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d02c5302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base data path: /home/jovyan/Notebooks/DATA\n",
      "Attack CSV: /home/jovyan/Notebooks/DATA/attack_data/attack_samples_1sec.csv\n",
      "Benign CSV: /home/jovyan/Notebooks/DATA/benign_data/benign_samples_1sec.csv\n",
      "Attack shape: (90391, 94)\n",
      "Benign shape: (136800, 94)\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(\"/home/jovyan/Notebooks/.env\")\n",
    "base_path = os.getenv(\"DATA_PATH\")\n",
    "# Sanity check\n",
    "print(\"Base data path:\", base_path)\n",
    "\n",
    "attack_file = \"attack_samples_1sec.csv\"\n",
    "benign_file = \"benign_samples_1sec.csv\"\n",
    "\n",
    "attack_path = os.path.join(base_path, \"attack_data\", attack_file)\n",
    "benign_path = os.path.join(base_path, \"benign_data\", benign_file)\n",
    "\n",
    "# Sanity check\n",
    "print(\"Attack CSV:\", attack_path)\n",
    "print(\"Benign CSV:\", benign_path)\n",
    "\n",
    "# Loading CSVs (Preview mode)\n",
    "df_attack = pd.read_csv(attack_path, low_memory=False)\n",
    "df_benign = pd.read_csv(benign_path, low_memory=False)\n",
    "\n",
    "# Check if loaded (print shape)\n",
    "print(\"Attack shape:\", df_attack.shape)\n",
    "print(\"Benign shape:\", df_benign.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c0939f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined shape: (227191, 95)\n",
      "         device_name         device_mac  \\\n",
      "0         plug-flame  d4:a6:51:20:91:f7   \n",
      "1  ultrasonic-sensor  08:b6:1f:82:ee:c4   \n",
      "2   plug-all-sensors  d4:a6:51:82:98:a8   \n",
      "3             router  28:87:ba:bd:c6:6c   \n",
      "4   vibration-sensor  08:b6:1f:82:27:d0   \n",
      "\n",
      "                                         label_full  label1  label2  \\\n",
      "0                             benign_whole-network3  benign  benign   \n",
      "1                             benign_whole-network3  benign  benign   \n",
      "2  attack_recon_host-disc-udp-ping_plug-all-sensors  attack   recon   \n",
      "3            attack_mitm_ip-spoofing_router--switch  attack    mitm   \n",
      "4              attack_recon_port-scan_whole-network  attack   recon   \n",
      "\n",
      "               label3                    label4  \\\n",
      "0              benign                    benign   \n",
      "1              benign                    benign   \n",
      "2  host-disc-udp-ping  recon_host-disc-udp-ping   \n",
      "3         ip-spoofing          mitm_ip-spoofing   \n",
      "4           port-scan           recon_port-scan   \n",
      "\n",
      "                                           timestamp  \\\n",
      "0  2025-09-09T14:16:38.400000Z_2025-09-09T14:16:3...   \n",
      "1  2025-09-09T14:41:23.400000Z_2025-09-09T14:41:2...   \n",
      "2  2025-01-16T13:48:12.048000Z_2025-01-16T13:48:1...   \n",
      "3  2025-02-14T01:21:47.621000Z_2025-02-14T01:21:4...   \n",
      "4  2025-01-15T13:05:02.516000Z_2025-01-15T13:05:0...   \n",
      "\n",
      "               timestamp_start                timestamp_end  ...  \\\n",
      "0  2025-09-09T14:16:38.400000Z  2025-09-09T14:16:39.400000Z  ...   \n",
      "1  2025-09-09T14:41:23.400000Z  2025-09-09T14:41:24.400000Z  ...   \n",
      "2  2025-01-16T13:48:12.048000Z  2025-01-16T13:48:13.048000Z  ...   \n",
      "3  2025-02-14T01:21:47.621000Z  2025-02-14T01:21:48.621000Z  ...   \n",
      "4  2025-01-15T13:05:02.516000Z  2025-01-15T13:05:03.516000Z  ...   \n",
      "\n",
      "   network_time-delta_std_deviation  network_ttl_avg  network_ttl_max  \\\n",
      "0                          0.000000         0.000000              0.0   \n",
      "1                          0.016731       159.500000            255.0   \n",
      "2                          0.003678       151.476496            255.0   \n",
      "3                          0.000077        63.995786             64.0   \n",
      "4                          0.017448       159.500000            255.0   \n",
      "\n",
      "   network_ttl_min network_ttl_std_deviation  network_window-size_avg  \\\n",
      "0              0.0                  0.000000                 0.000000   \n",
      "1             64.0                 95.500000             34826.000000   \n",
      "2             37.0                103.616617              1972.000000   \n",
      "3              1.0                  0.480594              6947.333333   \n",
      "4             64.0                 95.500000             34454.500000   \n",
      "\n",
      "   network_window-size_max  network_window-size_min  \\\n",
      "0                      0.0                      0.0   \n",
      "1                  64062.0                   5590.0   \n",
      "2                   2920.0                   1024.0   \n",
      "3                  15008.0                    282.0   \n",
      "4                  64075.0                   4834.0   \n",
      "\n",
      "   network_window-size_std_deviation  source_file  \n",
      "0                           0.000000       benign  \n",
      "1                       29236.000000       benign  \n",
      "2                         948.000000       attack  \n",
      "3                        6874.529855       attack  \n",
      "4                       29620.500000       attack  \n",
      "\n",
      "[5 rows x 95 columns]\n"
     ]
    }
   ],
   "source": [
    "# Add source file column to identify the origin of each sample\n",
    "df_attack[\"source_file\"] = \"attack\"\n",
    "df_benign[\"source_file\"] = \"benign\"\n",
    "\n",
    "# Combine datasets\n",
    "df = pd.concat([df_attack, df_benign], ignore_index=True)\n",
    "\n",
    "# shuffle the combined dataset\n",
    "df = df.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "\n",
    "# Check combined shape\n",
    "print(\"Combined shape:\", df.shape)\n",
    "\n",
    "# Preview the first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1c371f",
   "metadata": {},
   "source": [
    "### 2. Clean & Prepare Features\n",
    "\n",
    "**Goals:**\n",
    "- Choose the target label column: we’ll use `label2` (attack category).\n",
    "- Drop raw identifier / list-like columns (IPs, ports, MACs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0253aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"label2\" # Target column name\n",
    "\n",
    "# checking it exists in the dataframe\n",
    "if TARGET not in df.columns:\n",
    "    raise ValueError(f\"Target column '{TARGET}' not found in the dataframe.\")\n",
    "\n",
    "# Drop raw identifiers / list-like text columns, which are not useful for modeling\n",
    "drop_cols = [\n",
    "    \"device_mac\",\n",
    "    \"network_ips_all\",\"network_ips_dst\",\"network_ips_src\",\n",
    "    \"network_macs_all\",\"network_macs_dst\",\"network_macs_src\",\n",
    "    \"network_ports_all\",\"network_ports_dst\",\"network_ports_src\",\n",
    "    \"network_protocols_all\",\"network_protocols_dst\",\"network_protocols_src\",\n",
    "]\n",
    "drop_cols = [c for c in drop_cols if c in df.columns]\n",
    "df.drop(columns=drop_cols, inplace=True, errors=\"ignore\")\n",
    "\n",
    "#\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
